{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b92ad14f",
   "metadata": {},
   "source": [
    "# Pandas Comprehensive Tutorial\n",
    "============================\n",
    "\n",
    "This script provides a complete introduction to pandas, including:\n",
    "- What is pandas and how it works\n",
    "- Series and DataFrame concepts\n",
    "- Common operations and indexing\n",
    "- Conditional indexing and data wrangling\n",
    "- Interactive exercises for students\n",
    "- Complex exercises to test understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9f12ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ea772d",
   "metadata": {},
   "source": [
    "# SECTION 1: WHAT IS PANDAS?\n",
    "\n",
    "Pandas is a powerful Python library for data manipulation and analysis. \n",
    "It provides data structures for efficiently storing and manipulating \n",
    "large datasets, along with tools for reading and writing data in \n",
    "various formats.\n",
    "\n",
    "Key Features:\n",
    "- DataFrame: 2D labeled data structure (like a spreadsheet)\n",
    "- Series: 1D labeled array (like a column in a spreadsheet)\n",
    "- Powerful indexing and selection capabilities\n",
    "- Built-in data cleaning and preparation tools\n",
    "- Integration with other data science libraries\n",
    "- Fast performance for large datasets\n",
    "\n",
    "Think of pandas as 'Excel on steroids' for Python!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de03d1d",
   "metadata": {},
   "source": [
    "## Datatypes in Python vs Pandas vs Numpy\n",
    "\n",
    "![](../images/dtypes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b8b870",
   "metadata": {},
   "source": [
    "# SECTION 2: SERIES - THE BUILDING BLOCK\n",
    "\n",
    "A Series is a one-dimensional labeled array that can hold any data type.\n",
    "\n",
    "It's like a column in a spreadsheet with an index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce50a1c8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64064be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From a list\n",
    "numbers = [10, 20, 30, 40, 50.3]\n",
    "series_from_list = pd.Series(numbers)\n",
    "print(\"Series from list:\")\n",
    "series_from_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588164fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From a list with custom index\n",
    "custom_index = ['A', 'B', 'C', 'D', 'E']\n",
    "series_custom_index = pd.Series(numbers, index=custom_index)\n",
    "print(\"Series with custom index:\")\n",
    "\n",
    "series_custom_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad935df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From a dictionary\n",
    "data_dict = {'Jan': 100, 'Feb': 150, 'Mar': 200, 'Apr': 175}\n",
    "series_from_dict = pd.Series(data_dict)\n",
    "print(\"Series from dictionary:\")\n",
    "series_from_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2af0d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_from_dict['Jan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a74791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series operations\n",
    "print(\"--- Series Operations ---\")\n",
    "print(\"Original series:\", series_from_list)\n",
    "print(\"Sum:\", series_from_list.sum())\n",
    "print(\"Mean:\", series_from_list.mean())\n",
    "print(\"Max:\", series_from_list.max())\n",
    "print(\"Min:\", series_from_list.min())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76646f9",
   "metadata": {},
   "source": [
    "# SECTION 3: DATAFRAME - THE POWERHOUSE\n",
    "\n",
    "A DataFrame is a 2D labeled data structure with columns that can be \n",
    "different types (numeric, string, boolean, etc.). Think of it as a \n",
    "collection of Series objects, or a spreadsheet with multiple columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc72d552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From a dictionary\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n",
    "    'Age': [25, 30, 35, 28, 32],\n",
    "    'City': ['NYC', 'LA', 'Chicago', 'Boston', 'Seattle'],\n",
    "    'Salary': [50000, 60000, 70000, 55000, 65000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"DataFrame from dictionary:\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32547bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From a list of lists\n",
    "data_list = [\n",
    "    ['Apple', 'Fruit', 0.5, 100],\n",
    "    ['Carrot', 'Vegetable', 0.3, 50],\n",
    "    ['Chicken', 'Meat', 8.0, 200],\n",
    "    ['Rice', 'Grain', 2.0, 150],\n",
    "    ['Pizza', 'Meat', 10.0, 250],\n",
    "    ['Potato', 'Vegetable', 0.5, 100]\n",
    "]\n",
    "\n",
    "columns = ['Food', 'Category', 'Price', 'Calories']\n",
    "df_food = pd.DataFrame(data_list, columns=columns)\n",
    "print(\"DataFrame from list of lists:\")\n",
    "\n",
    "df_food\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16296364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic DataFrame information\n",
    "print(\"--- DataFrame Information ---\")\n",
    "print(\"Shape (rows, columns):\", df_food.shape)\n",
    "print(\"Data types:\")\n",
    "print(df_food.dtypes)\n",
    "print(\"\\nColumn names:\", list(df_food.columns))\n",
    "print(\"Index:\", list(df_food.index))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60379492",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food.columns = ['Food', 'Category', 'Price', 'Calories']\n",
    "df_food"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3568e4",
   "metadata": {},
   "source": [
    "# SECTION 4: INDEXING AND SELECTION\n",
    "\n",
    "Pandas provides powerful ways to select and filter data. Understanding \n",
    "indexing is crucial for effective data manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0ccd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From a dictionary\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n",
    "    'Age': [25, 30, 35, 28, 32],\n",
    "    'City': ['NYC', 'LA', 'Chicago', 'Boston', 'Seattle'],\n",
    "    'Salary': [50000, 60000, 70000, 55000, 65000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"DataFrame from dictionary:\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90218cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column selection\n",
    "print(\"--- Column Selection ---\")\n",
    "print(\"Select single column (returns Series):\")\n",
    "print(df['Name'])\n",
    "print(type(df['Name']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cef36b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Select multiple columns (returns DataFrame):\")\n",
    "df[['Name', 'Age', 'Salary']]\n",
    "# type(df[['Name', 'Age', 'Salary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3390c7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row selection\n",
    "print(\"--- Row Selection ---\")\n",
    "print(\"Select first 3 rows:\")\n",
    "print(df.head(3))\n",
    "print()\n",
    "\n",
    "print(\"Select last 2 rows:\")\n",
    "print(df.tail(2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3fd846",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[2, 4], ['Age', 'Salary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c122b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cb637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food['Category'] == 'Vegetable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8d9a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food.loc[df_food['Category'] == 'Vegetable', 'Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b425a11e",
   "metadata": {},
   "source": [
    "## Indexing: loc vs iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ede7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978a0fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position-based indexing with .iloc\n",
    "print(\"--- Position-based Indexing (.iloc) ---\")\n",
    "print(\"First row (index 0):\")\n",
    "print(df.iloc[0])\n",
    "print(type(df.iloc[0]))\n",
    "\n",
    "print(\"First 2 rows, first 2 columns:\")\n",
    "print(df.iloc[0:2, 0:2])\n",
    "print(type(df.iloc[0:2, 0:2]))\n",
    "\n",
    "print(\"Specific row and column (row 1, column 'Age'):\")\n",
    "print(df.iloc[1]['Age'])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af85d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label-based indexing with .loc\n",
    "print(\"--- Label-based Indexing (.loc) ---\")\n",
    "print(\"Select rows by index label:\")\n",
    "print(df.loc[0:3])\n",
    "print()\n",
    "\n",
    "print(\"Select specific row and column:\")\n",
    "print(df.loc[0, 'Name'])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8efd7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12776ab",
   "metadata": {},
   "source": [
    "# SECTION 5: CONDITIONAL INDEXING\n",
    "\n",
    "Conditional indexing (boolean indexing) allows you to filter data \n",
    "based on conditions, similar to WHERE clauses in SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7691e0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] > 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a16c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple conditions\n",
    "print(\"--- Simple Conditions ---\")\n",
    "print(\"People older than 30:\")\n",
    "print(df[df['Age'] > 30])\n",
    "print()\n",
    "\n",
    "print(\"People with salary >= 60000:\")\n",
    "df[df['Salary'] >= 60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c32208",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4357a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple conditions\n",
    "# & and \n",
    "# | or\n",
    "# ~ not\n",
    "\n",
    "print(\"--- Multiple Conditions ---\")\n",
    "print(\"People aged 25-30 AND salary < 60000:\")\n",
    "condition = ((df['Age'] >= 25) & (df['Age'] <= 30)) | ~(df['Salary'] >= 60000)\n",
    "\n",
    "df[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc1304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~(df['Salary'] >= 60000)]\n",
    "# df['Salary'] >= 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e94b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "~(df['Salary'] >= 60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1c098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17359e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# String conditions\n",
    "print(\"--- String Conditions ---\")\n",
    "print(\"People from cities starting with 'B':\")\n",
    "print(df[df['City'].str.startswith('B')])\n",
    "print()\n",
    "\n",
    "print(\"People with names containing 'a' (case insensitive):\")\n",
    "df[df['Name'].str.contains('a', case=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c75d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isin() method\n",
    "print(\"--- Using isin() ---\")\n",
    "print(\"People from NYC or LA:\")\n",
    "list_of_cities = ['NYC', 'LA', \"Boston\"]\n",
    "df[~(df['City'].isin(list_of_cities)) & (df['Salary'] > 65000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c237aaa1",
   "metadata": {},
   "source": [
    "# SECTION 6: DATA WRANGLING\n",
    "\n",
    "Data wrangling involves cleaning, transforming, and preparing data \n",
    "for analysis. Pandas provides many tools for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6e6275",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3833a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding/removing columns\n",
    "print(\"--- Adding/Removing Columns ---\")\n",
    "df['Experience'] = df['Age'] - 22  # Assuming they started working at 22\n",
    "print(\"Added Experience column:\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2416f9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove a column\n",
    "df = df.drop('Experience', axis=1)\n",
    "print(\"After dropping Experience column:\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18b68af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58b7cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting\n",
    "print(\"--- Sorting ---\")\n",
    "print(\"Sort by Age (ascending):\")\n",
    "print(df.sort_values('Age'))\n",
    "print()\n",
    "\n",
    "print(\"Sort by Salary (descending):\")\n",
    "print(df.sort_values('Salary', ascending=False))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f4609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve', 'Frank', 'George', 'Hannah', 'Ivy', 'Jack'],\n",
    "    'Age': [25, 30, 35, 28, 32, np.nan, 31, 27, 26, 33],\n",
    "    'City': ['NYC', 'LA', 'Chicago', 'Boston', 'Seattle', 'Chicago', 'NYC', 'LA', 'Chicago', 'Boston'],\n",
    "    'Salary': [50000, 60000, np.nan, 55000, 65000, 55000, 65000, 55000, None, 55000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c47664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping and aggregation\n",
    "print(\"--- Grouping and Aggregation ---\")\n",
    "print(\"Average salary by city:\")\n",
    "city_salary = df.groupby('City')['Salary'].agg(['mean', 'count', 'min', 'max', 'sum']).reset_index()\n",
    "city_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31b342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(np.nan)\n",
    "# None == np.nan\n",
    "# np.nan == np.nan\n",
    "np.nan == None\n",
    "np.nan == False\n",
    "np.nan == True\n",
    "np.nan == 0\n",
    "np.nan == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a977cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing data\n",
    "print(\"--- Handling Missing Data ---\")\n",
    "df_with_nulls = df.copy()\n",
    "df_with_nulls.loc[2, 'Salary'] = np.nan # Not a Number NaN\n",
    "df_with_nulls.loc[1, 'Age'] = np.nan\n",
    "df_with_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bd404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_nulls.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081a6779",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled = df_with_nulls.fillna({'Salary': df_with_nulls['Salary'].mean(), 'Age': df_with_nulls['Age'].median()})\n",
    "df_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0cd38c",
   "metadata": {},
   "source": [
    "# SECTION 7: ADVANCED DATAFRAME MANIPULATION\n",
    "\n",
    "Advanced DataFrame manipulation includes merging/joining data (similar to SQL JOINs)\n",
    "and sophisticated grouping operations. These are essential skills for working\n",
    "with multiple datasets and complex data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a348da",
   "metadata": {},
   "source": [
    "## Merge and Join Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fc94c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customers DataFrame\n",
    "customers = pd.DataFrame({\n",
    "    'customer_id': [1, 2, 3, 4, 5],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n",
    "    'email': ['alice@email.com', 'bob@email.com', 'charlie@email.com', 'diana@email.com', 'eve@email.com'],\n",
    "    'city': ['NYC', 'LA', 'Chicago', 'Boston', 'Seattle']\n",
    "})\n",
    "customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc6c70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orders DataFrame\n",
    "orders = pd.DataFrame({\n",
    "    'order_id': [101, 102, 103, 104, 105, 106, 107],\n",
    "    'customer_id': [1, 2, 1, 3, 4, 2, 10],\n",
    "    'product': ['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Headphones', 'Tablet', 'Phone'],\n",
    "    'amount': [999, 25, 75, 299, 150, 399, 100],\n",
    "    'order_date': ['2024-01-15', '2024-01-16', '2024-01-17', '2024-01-18', '2024-01-19', '2024-01-20', '2024-01-21']\n",
    "})\n",
    "\n",
    "print(\"Orders DataFrame:\")\n",
    "orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e51e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner Join (default merge type)\n",
    "print(\"--- Inner Join (default) ---\")\n",
    "print(\"Combines rows where customer_id exists in both DataFrames:\")\n",
    "inner_merge = pd.merge(customers, orders, on='customer_id', how='inner')\n",
    "inner_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9567db5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b40ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left Join\n",
    "print(\"--- Left Join ---\")\n",
    "print(\"Keeps all rows from left DataFrame (customers):\")\n",
    "left_merge = pd.merge(customers, orders, on='customer_id', how='left')\n",
    "left_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa6eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_merge[left_merge[\"order_id\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7ed44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right Join\n",
    "print(\"--- Right Join ---\")\n",
    "print(\"Keeps all rows from right DataFrame (orders):\")\n",
    "right_merge = pd.merge(customers, orders, on='customer_id', how='right')\n",
    "right_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fc3bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer Join\n",
    "print(\"--- Outer Join ---\")\n",
    "print(\"Keeps all rows from both DataFrames:\")\n",
    "outer_merge = pd.merge(customers, orders, on='customer_id', how='outer')\n",
    "outer_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd66485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with different column names\n",
    "print(\"--- Merge with Different Column Names ---\")\n",
    "print(\"When joining columns have different names:\")\n",
    "\n",
    "customers_alt = customers.copy()\n",
    "customers_alt.rename(columns={'customer_id': 'cust_id'}, inplace=True)\n",
    "\n",
    "print(\"Customers with renamed column:\")\n",
    "customers_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc487d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Merge using left_on and right_on:\")\n",
    "merge_different_names = pd.merge(customers_alt, orders, \n",
    "                                left_on='cust_id', right_on='customer_id', \n",
    "                                how='inner')\n",
    "merge_different_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a5f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple key merge\n",
    "print(\"--- Multiple Key Merge ---\")\n",
    "print(\"Merging on multiple columns:\")\n",
    "\n",
    "# Create DataFrames with multiple keys\n",
    "employees = pd.DataFrame({\n",
    "    'dept_id': [1, 1, 2, 2, 3],\n",
    "    'emp_id': [101, 102, 201, 202, 301],\n",
    "    'name': ['John', 'Jane', 'Bob', 'Alice', 'Charlie'],\n",
    "    'salary': [50000, 55000, 60000, 65000, 70000]\n",
    "})\n",
    "\n",
    "departments = pd.DataFrame({\n",
    "    'dept_id': [1, 1, 2, 2, 3],\n",
    "    'emp_id': [101, 102, 201, 202, 301],\n",
    "    'dept_name': ['IT', 'IT', 'HR', 'HR', 'Finance'],\n",
    "    'location': ['Floor 1', 'Floor 1', 'Floor 2', 'Floor 2', 'Floor 3']\n",
    "})\n",
    "\n",
    "employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e998d4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "departments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba625ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Merge on multiple keys (dept_id and emp_id):\")\n",
    "multi_key_merge = pd.merge(employees, departments, on=['dept_id', 'emp_id'])\n",
    "multi_key_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd32b66",
   "metadata": {},
   "source": [
    "## Advanced GroupBy Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2824fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced GroupBy Operations\n",
    "print(\"--- Advanced GroupBy Operations ---\")\n",
    "print(\"GroupBy is one of pandas' most powerful features for data analysis.\")\n",
    "\n",
    "# Create a more complex dataset for grouping\n",
    "sales_data = pd.DataFrame({\n",
    "    'date': pd.date_range('2024-01-01', periods=20, freq='D'),\n",
    "    'region': ['North', 'South', 'East', 'West'] * 5,\n",
    "    'product': ['A', 'B', 'C', 'D'] * 5,\n",
    "    'sales_amount': np.random.randint(100, 1000, 20),\n",
    "    'units_sold': np.random.randint(10, 100, 20),\n",
    "    'salesperson': ['John', 'Jane', 'Bob', 'Alice'] * 5\n",
    "})\n",
    "\n",
    "print(\"Sales Data:\")\n",
    "sales_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2293cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic grouping\n",
    "print(\"--- Basic Grouping ---\")\n",
    "print(\"Group by region and calculate total sales:\")\n",
    "region_sales = sales_data.groupby('region')['sales_amount'].sum().reset_index()\n",
    "region_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c87d375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple aggregations\n",
    "print(\"--- Multiple Aggregations ---\")\n",
    "print(\"Group by region and calculate multiple statistics:\")\n",
    "region_stats = sales_data.groupby('region').agg({\n",
    "    'sales_amount': ['sum', 'count', 'std'],\n",
    "    'units_sold': ['sum', 'mean', 'max', 'min']\n",
    "})\n",
    "region_stats.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb43e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by multiple columns\n",
    "print(\"--- Group by Multiple Columns ---\")\n",
    "print(\"Group by region and product:\")\n",
    "region_product = sales_data.groupby(['region', 'product']).agg({\n",
    "    'sales_amount': 'sum',\n",
    "    'units_sold': 'sum'\n",
    "}).reset_index()\n",
    "region_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c153700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom aggregation functions\n",
    "print(\"--- Custom Aggregation Functions ---\")\n",
    "print(\"Group by salesperson and calculate custom metrics:\")\n",
    "\n",
    "def custom_agg(x):\n",
    "    return pd.Series({\n",
    "        'total_sales': x['sales_amount'].sum(),\n",
    "        'avg_order_value': x['sales_amount'].mean(),\n",
    "        'num_orders': len(x),\n",
    "        'best_day': x.loc[x['sales_amount'].idxmax(), 'date']\n",
    "    })\n",
    "\n",
    "salesperson_analysis = sales_data.groupby('salesperson').apply(custom_agg)\n",
    "salesperson_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40abd3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform operations\n",
    "print(\"--- Transform Operations ---\")\n",
    "print(\"Add columns with group-level calculations:\")\n",
    "\n",
    "# Calculate percentage of total sales by region\n",
    "sales_data['pct_of_region'] = sales_data.groupby('region')['sales_amount'].transform(\n",
    "    lambda x: x / x.sum() * 100\n",
    ")\n",
    "\n",
    "sales_data[sales_data[\"region\"] == \"North\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451a6aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(sales_data['pct_of_region'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020b8e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ccbb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot tables\n",
    "print(\"--- Pivot Tables ---\")\n",
    "print(\"Create a pivot table showing sales by region and product:\")\n",
    "pivot_table = sales_data.pivot_table(\n",
    "    values='units_sold',\n",
    "    index=['region', 'product'],\n",
    "    columns='salesperson',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79442726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter within groups\n",
    "print(\"--- Filter Within Groups ---\")\n",
    "print(\"Keep only top 2 sales days per region:\")\n",
    "\n",
    "def top_n_sales(group, n=2):\n",
    "    return group.nlargest(n, 'sales_amount')\n",
    "\n",
    "top_sales_by_region = sales_data.groupby('region').apply(top_n_sales)\n",
    "print(\"Top 2 sales days per region:\")\n",
    "\n",
    "top_sales_by_region[['region', 'date', 'sales_amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3506af52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Apply with GroupBy ---\n",
      "Apply functions to groups of data:\n",
      "Sales data for grouping:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>product</th>\n",
       "      <th>sales</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>North</td>\n",
       "      <td>A</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South</td>\n",
       "      <td>B</td>\n",
       "      <td>150</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>East</td>\n",
       "      <td>C</td>\n",
       "      <td>200</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>West</td>\n",
       "      <td>A</td>\n",
       "      <td>120</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>North</td>\n",
       "      <td>B</td>\n",
       "      <td>180</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South</td>\n",
       "      <td>C</td>\n",
       "      <td>220</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>East</td>\n",
       "      <td>A</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West</td>\n",
       "      <td>B</td>\n",
       "      <td>160</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>North</td>\n",
       "      <td>C</td>\n",
       "      <td>190</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>South</td>\n",
       "      <td>A</td>\n",
       "      <td>110</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>East</td>\n",
       "      <td>B</td>\n",
       "      <td>170</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>West</td>\n",
       "      <td>C</td>\n",
       "      <td>210</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   region product  sales  cost\n",
       "0   North       A    100    60\n",
       "1   South       B    150    90\n",
       "2    East       C    200   120\n",
       "3    West       A    120    70\n",
       "4   North       B    180   100\n",
       "5   South       C    220   130\n",
       "6    East       A     90    50\n",
       "7    West       B    160    85\n",
       "8   North       C    190   110\n",
       "9   South       A    110    65\n",
       "10   East       B    170    95\n",
       "11   West       C    210   125"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply with groupby\n",
    "print(\"--- Apply with GroupBy ---\")\n",
    "print(\"Apply functions to groups of data:\")\n",
    "\n",
    "# Create sales data for grouping\n",
    "sales_group_data = pd.DataFrame({\n",
    "    'region': ['North', 'South', 'East', 'West'] * 3,\n",
    "    'product': ['A', 'B', 'C'] * 4,\n",
    "    'sales': [100, 150, 200, 120, 180, 220, 90, 160, 190, 110, 170, 210],\n",
    "    'cost': [60, 90, 120, 70, 100, 130, 50, 85, 110, 65, 95, 125]\n",
    "})\n",
    "\n",
    "print(\"Sales data for grouping:\")\n",
    "sales_group_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "08c4278c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group analysis by region:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_sales</th>\n",
       "      <th>total_cost</th>\n",
       "      <th>profit</th>\n",
       "      <th>profit_margin</th>\n",
       "      <th>avg_sale</th>\n",
       "      <th>num_transactions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>East</th>\n",
       "      <td>460.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>42.391304</td>\n",
       "      <td>153.333333</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North</th>\n",
       "      <td>470.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>42.553191</td>\n",
       "      <td>156.666667</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South</th>\n",
       "      <td>480.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>40.625000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West</th>\n",
       "      <td>490.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>163.333333</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total_sales  total_cost  profit  profit_margin    avg_sale  \\\n",
       "region                                                               \n",
       "East          460.0       265.0   195.0      42.391304  153.333333   \n",
       "North         470.0       270.0   200.0      42.553191  156.666667   \n",
       "South         480.0       285.0   195.0      40.625000  160.000000   \n",
       "West          490.0       280.0   210.0      42.857143  163.333333   \n",
       "\n",
       "        num_transactions  \n",
       "region                    \n",
       "East                 3.0  \n",
       "North                3.0  \n",
       "South                3.0  \n",
       "West                 3.0  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply custom function to each group\n",
    "def analyze_group(group):\n",
    "    return pd.Series({\n",
    "        'total_sales': group['sales'].sum(),\n",
    "        'total_cost': group['cost'].sum(),\n",
    "        'profit': group['sales'].sum() - group['cost'].sum(),\n",
    "        'profit_margin': (group['sales'].sum() - group['cost'].sum()) / group['sales'].sum() * 100,\n",
    "        'avg_sale': group['sales'].mean(),\n",
    "        'num_transactions': len(group)\n",
    "    })\n",
    "\n",
    "# Apply to groups\n",
    "group_analysis = sales_group_data.groupby('region').apply(analyze_group)\n",
    "print(\"Group analysis by region:\")\n",
    "group_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb80a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-tabulation\n",
    "print(\"--- Cross-Tabulation ---\")\n",
    "print(\"Cross-tab of region vs product:\")\n",
    "cross_tab = pd.crosstab(sales_data['region'], sales_data['product'], \n",
    "                        values=sales_data['sales_amount'], aggfunc='sum')\n",
    "cross_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5714c9",
   "metadata": {},
   "source": [
    "# SECTION 8: THE POWERFUL APPLY METHOD\n",
    "\n",
    "The apply method is one of pandas' most versatile tools, allowing you to apply\n",
    "custom functions to DataFrames, Series, or groups of data. It's like having\n",
    "a Swiss Army knife for data transformation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c092c9",
   "metadata": {},
   "source": [
    "## Apply on Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d086c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample Series\n",
    "sample_series = pd.Series([1, 4, 9, 16, 25, 36, 49, 64, 81, 100])\n",
    "print(\"Original Series:\")\n",
    "sample_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f10a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply mathematical functions\n",
    "print(\"Square root of each number:\")\n",
    "sqrt_series = sample_series.apply(np.sqrt)\n",
    "sqrt_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9da3c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply custom function\n",
    "def categorize_number(x):\n",
    "    if x < 10:\n",
    "        return 'Small'\n",
    "    elif x < 50:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'Large'\n",
    "\n",
    "print(\"Categorize numbers by size:\")\n",
    "categorized = sample_series.apply(categorize_number)\n",
    "categorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ada614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply with lambda functions\n",
    "print(\"Double each number:\")\n",
    "doubled = sample_series.apply(lambda x: x * 2)\n",
    "doubled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350bf5bd",
   "metadata": {},
   "source": [
    "\n",
    "## Apply on DataFrame columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c779ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply on DataFrame columns\n",
    "print(\"--- Apply on DataFrame Columns ---\")\n",
    "print(\"Apply functions to entire columns:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd0920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n",
    "    'age': [25, 30, 35, 28, 32],\n",
    "    'salary': [50000, 60000, 70000, 55000, 65000],\n",
    "    'department': ['IT', 'HR', 'IT', 'Finance', 'Marketing']\n",
    "})\n",
    "\n",
    "print(\"Sample DataFrame:\")\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79b4454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to string columns\n",
    "print(\"Convert names to uppercase:\")\n",
    "sample_df['name'] = sample_df['name'].apply(lambda x: x.upper())\n",
    "sample_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fed9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to numeric columns\n",
    "print(\"Calculate salary with 10% bonus:\")\n",
    "sample_df['bonus'] = sample_df['salary'].apply(lambda x: x * 0.10)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to multiple columns\n",
    "print(\"Calculate total compensation (salary + bonus):\")\n",
    "sample_df['total_comp'] = sample_df.apply(\n",
    "    lambda row: row['salary'] + row['bonus'], axis=1\n",
    ")\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c075bf8",
   "metadata": {},
   "source": [
    "## Apply on DataFrame rows (axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3476d93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a more complex DataFrame\n",
    "employees = pd.DataFrame({\n",
    "    'first_name': ['John', 'Jane', 'Bob', 'Alice', 'Charlie'],\n",
    "    'last_name': ['Smith', 'Doe', 'Johnson', 'Brown', 'Wilson'],\n",
    "    'hours_worked': [40, 35, 45, 38, 42],\n",
    "    'hourly_rate': [25, 30, 22, 28, 26],\n",
    "    'overtime_hours': [5, 0, 10, 2, 8]\n",
    "})\n",
    "\n",
    "print(\"Employees DataFrame:\")\n",
    "employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aba68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weekly pay for each employee\n",
    "def calculate_weekly_pay(row):\n",
    "    regular_pay = row['hours_worked'] * row['hourly_rate']\n",
    "    overtime_pay = row['overtime_hours'] * row['hourly_rate'] * 1.5\n",
    "    return regular_pay + overtime_pay\n",
    "\n",
    "employees['weekly_pay'] = employees.apply(calculate_weekly_pay, axis=1)\n",
    "print(\"Employees with weekly pay calculation:\")\n",
    "employees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8de7570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply with conditional logic\n",
    "def categorize_employee(row):\n",
    "    if row['weekly_pay'] > 1500:\n",
    "        return 'High Earner'\n",
    "    elif row['weekly_pay'] > 1000:\n",
    "        return 'Medium Earner'\n",
    "    else:\n",
    "        return 'Low Earner'\n",
    "\n",
    "employees['earner_category'] = employees.apply(categorize_employee, axis=1)\n",
    "print(\"Employees with earning categories:\")\n",
    "employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b25dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply with multiple return values\n",
    "def analyze_employee(row):\n",
    "    efficiency = row['hours_worked'] / (row['hours_worked'] + row['overtime_hours'])\n",
    "    cost_per_hour = row['weekly_pay'] / (row['hours_worked'] + row['overtime_hours'])\n",
    "    return pd.Series({\n",
    "        'efficiency': round(efficiency, 2),\n",
    "        'cost_per_hour': round(cost_per_hour, 2)\n",
    "    })\n",
    "\n",
    "# Apply and expand results\n",
    "analysis_results = employees.apply(analyze_employee, axis=1)\n",
    "analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd3faf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees = pd.concat([employees, analysis_results], axis=1)\n",
    "employees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a86734",
   "metadata": {},
   "source": [
    "## Vectorized operations vs apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "cb9ea648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Vectorized Operations vs Apply ---\n",
      "When to use apply vs vectorized operations:\n",
      "Large dataset shape: (10000000, 2)\n",
      "\n",
      "Vectorized operation (recommended):\n",
      "Result shape: (10000000,)\n",
      "First 5 values: [0.17059513 1.68615053 8.75483424 2.66142221 1.43857283]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Vectorized Operations vs Apply ---\")\n",
    "print(\"When to use apply vs vectorized operations:\")\n",
    "\n",
    "# Create a large dataset for comparison\n",
    "large_data = pd.DataFrame({\n",
    "    'x': np.random.randn(10000000),\n",
    "    'y': np.random.randn(10000000)\n",
    "})\n",
    "\n",
    "print(\"Large dataset shape:\", large_data.shape)\n",
    "print()\n",
    "\n",
    "# Vectorized operation (faster)\n",
    "print(\"Vectorized operation (recommended):\")\n",
    "vectorized_result = large_data['x'] ** 2 + large_data['y'] ** 2\n",
    "print(\"Result shape:\", vectorized_result.shape)\n",
    "print(\"First 5 values:\", vectorized_result.head().values)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "cecdd7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.473697</td>\n",
       "      <td>1.314079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.431847</td>\n",
       "      <td>0.695701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.167145</td>\n",
       "      <td>-0.294532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.751994</td>\n",
       "      <td>-0.432979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.910059</td>\n",
       "      <td>-0.115126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>-0.771564</td>\n",
       "      <td>-2.139121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.437799</td>\n",
       "      <td>-0.454341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>-0.228791</td>\n",
       "      <td>1.136136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>-1.456464</td>\n",
       "      <td>-0.143452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.356348</td>\n",
       "      <td>0.384192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x         y\n",
       "0     2.473697  1.314079\n",
       "1     0.431847  0.695701\n",
       "2     1.167145 -0.294532\n",
       "3    -1.751994 -0.432979\n",
       "4    -1.910059 -0.115126\n",
       "...        ...       ...\n",
       "9995 -0.771564 -2.139121\n",
       "9996  0.437799 -0.454341\n",
       "9997 -0.228791  1.136136\n",
       "9998 -1.456464 -0.143452\n",
       "9999  0.356348  0.384192\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f04fe43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply operation (use sparingly for large datasets):\n",
      "Result shape: (10000000,)\n",
      "First 5 values: [0.17059513 1.68615053 8.75483424 2.66142221 1.43857283]\n",
      "\n",
      "Note: Vectorized operations are much faster for large datasets!\n",
      "Use apply when you need custom logic that can't be vectorized.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply operation (slower for large datasets)\n",
    "print(\"Apply operation (use sparingly for large datasets):\")\n",
    "def vector_operation(row):\n",
    "    return row['x'] ** 2 + row['y'] ** 2\n",
    "\n",
    "apply_result = large_data.apply(vector_operation, axis=1)\n",
    "print(\"Result shape:\", apply_result.shape)\n",
    "print(\"First 5 values:\", apply_result.head().values)\n",
    "print()\n",
    "\n",
    "print(\"Note: Vectorized operations are much faster for large datasets!\")\n",
    "print(\"Use apply when you need custom logic that can't be vectorized.\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26def77",
   "metadata": {},
   "source": [
    "# SECTION 9: STUDENT EXERCISES\n",
    "\n",
    "This document contains all the exercises from the pandas comprehensive tutorial, organized by difficulty level and concept area."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ec5ad0",
   "metadata": {},
   "source": [
    "### Exercise 1: Basic Creation\n",
    "**Objective:** Create Series and DataFrames from scratch\n",
    "\n",
    "**Tasks:**\n",
    "- Create a Series with the numbers 1, 4, 9, 16, 25 and labels 'a', 'b', 'c', 'd', 'e'\n",
    "- Create a DataFrame with columns: 'Product', 'Price', 'Stock' and at least 3 rows of data\n",
    "\n",
    "**Expected Output:** Series with square numbers, DataFrame with product information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010197bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data for reference\n",
    "sample_series_data = [1, 4, 9, 16, 25]\n",
    "sample_series_labels = ['a', 'b', 'c', 'd', 'e']\n",
    "\n",
    "sample_products = ['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Headphones']\n",
    "sample_prices = [999, 25, 75, 299, 150]\n",
    "sample_stock = [10, 50, 30, 15, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f1c187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "261010cb",
   "metadata": {},
   "source": [
    "### Exercise 2: Indexing and Selection\n",
    "**Objective:** Practice various indexing and selection methods\n",
    "\n",
    "**Tasks:** From the DataFrame 'df' created:\n",
    "- Select only the 'Name' and 'City' columns\n",
    "- Select the first 2 rows\n",
    "- Select people older than 28\n",
    "- Select people with salary between 50000 and 70000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118d3a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DataFrame for this exercise\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve', 'Frank', 'Grace'],\n",
    "    'Age': [25, 30, 35, 28, 32, 29, 27],\n",
    "    'City': ['NYC', 'LA', 'Chicago', 'Boston', 'Seattle', 'Miami', 'Denver'],\n",
    "    'Salary': [50000, 60000, 70000, 55000, 65000, 58000, 52000],\n",
    "    'Department': ['IT', 'HR', 'IT', 'Finance', 'Marketing', 'Sales', 'IT']\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c05edab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "899f8beb",
   "metadata": {},
   "source": [
    "### Exercise 3: Data Manipulation\n",
    "**Objective:** Learn basic data manipulation techniques\n",
    "\n",
    "**Tasks:** From the DataFrame 'df':\n",
    "- Add a new column 'Bonus' that is 10% of salary\n",
    "- Sort the data by age in descending order\n",
    "- Calculate the average salary by city\n",
    "- Find the person with the highest salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98958323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same DataFrame from Exercise 2\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve', 'Frank', 'Grace'],\n",
    "    'Age': [25, 30, 35, 28, 32, 29, 27],\n",
    "    'City': ['NYC', 'LA', 'Chicago', 'Boston', 'Seattle', 'Miami', 'Denver'],\n",
    "    'Salary': [50000, 60000, 70000, 55000, 65000, 58000, 52000],\n",
    "    'Department': ['IT', 'HR', 'IT', 'Finance', 'Marketing', 'Sales', 'IT']\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc83ea9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d814495",
   "metadata": {},
   "source": [
    "### Exercise 4: Conditional Operations\n",
    "**Objective:** Master conditional filtering and boolean indexing\n",
    "\n",
    "**Tasks:** Create a new DataFrame that contains:\n",
    "- People from cities with more than 3 letters\n",
    "- People whose names start with a vowel (A, E, I, O, U)\n",
    "- People with age + salary > 80000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb46c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve', 'Frank', 'Grace'],\n",
    "    'Age': [25, 30, 35, 28, 32, 29, 27],\n",
    "    'City': ['NYC', 'LA', 'Chicago', 'Boston', 'Seattle', 'Miami', 'Denver'],\n",
    "    'Salary': [50000, 60000, 70000, 55000, 65000, 58000, 52000],\n",
    "    'Department': ['IT', 'HR', 'IT', 'Finance', 'Marketing', 'Sales', 'IT']\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d638070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f888d721",
   "metadata": {},
   "source": [
    "### Exercise 5: Data Cleaning\n",
    "**Objective:** Practice handling missing data and data cleaning\n",
    "\n",
    "**Tasks:** \n",
    "- Identify all missing values\n",
    "- Fill numeric missing values with median\n",
    "- Fill string missing values with 'Unknown'\n",
    "- Remove any rows that still have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87b12f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DataFrame with missing values for this exercise\n",
    "df_missing = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve', 'Frank', 'Grace'],\n",
    "    'Age': [25, 30, np.nan, 28, 32, 29, np.nan],\n",
    "    'City': ['NYC', 'LA', 'Chicago', 'Boston', 'Seattle', np.nan, 'Denver'],\n",
    "    'Salary': [50000, 60000, 70000, 55000, 65000, 58000, 52000],\n",
    "    'Department': ['IT', 'HR', 'IT', 'Finance', 'Marketing', 'Sales', 'IT'],\n",
    "    'Experience': [2, 5, np.nan, 3, 7, 4, 1]\n",
    "})\n",
    "df_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcce2e67",
   "metadata": {},
   "source": [
    "### Exercise 6: Merge and Join Operations\n",
    "**Objective:** Master SQL-like JOIN operations in pandas\n",
    "\n",
    "**Required Operations:**\n",
    "- Perform an inner join to see all students with their courses\n",
    "- Perform a left join to see all students (even those without courses)\n",
    "- Perform a right join to see all courses (even those without students)\n",
    "- Calculate average GPA by major for students who have taken courses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6dfc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "students = pd.DataFrame({\n",
    "    'student_id': [1, 2, 3, 4, 5, 6, 7],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve', 'Frank', 'Grace'],\n",
    "    'major': ['CS', 'Math', 'CS', 'Physics', 'Math', 'Engineering', 'Biology'],\n",
    "    'gpa': [3.8, 3.5, 3.9, 3.7, 3.6, 3.4, 3.8]\n",
    "})\n",
    "\n",
    "# DataFrame 2: Courses\n",
    "courses = pd.DataFrame({\n",
    "    'course_id': [101, 102, 103, 104, 105, 106, 107, 108],\n",
    "    'student_id': [1, 1, 2, 3, 4, 5, 6, 7],\n",
    "    'course_name': ['Python', 'Data Structures', 'Calculus', 'Algorithms', 'Thermodynamics', 'Linear Algebra', 'Mechanics', 'Genetics'],\n",
    "    'grade': ['A', 'A-', 'B+', 'A', 'B', 'A-', 'B+', 'A']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bff5f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fce85fda",
   "metadata": {},
   "source": [
    "### Exercise 7: Advanced GroupBy Operations\n",
    "**Objective:** Master sophisticated grouping and aggregation\n",
    "\n",
    "**Required Operations:**\n",
    "- Group by region and calculate total sales, average order value, and count\n",
    "- Group by region and product to see sales breakdown\n",
    "- Find the top 3 salespeople by total sales\n",
    "- Calculate the percentage of total sales each product contributes\n",
    "- Create a pivot table showing sales by region and product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fce530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create date range for last 30 days\n",
    "dates = pd.date_range('2024-01-01', periods=30, freq='D')\n",
    "\n",
    "# Generate sample sales data\n",
    "np.random.seed(42)  # For reproducible results\n",
    "sales_data = pd.DataFrame({\n",
    "    'date': np.random.choice(dates, 100),\n",
    "    'product': np.random.choice(['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Headphones'], 100),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], 100),\n",
    "    'salesperson': np.random.choice(['John', 'Jane', 'Bob', 'Alice', 'Charlie'], 100),\n",
    "    'amount': np.random.randint(100, 2000, 100)\n",
    "})\n",
    "sales_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76e9273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b26e4c11",
   "metadata": {},
   "source": [
    "### Exercise 8: The Apply Method\n",
    "**Objective:** Master the versatile apply method for custom operations\n",
    "\n",
    "**Required Operations:**\n",
    "- Use apply to calculate the average score for each student\n",
    "- Use apply to categorize students as 'Excellent' (>90), 'Good' (80-90), 'Average' (70-80), 'Below Average' (<70)\n",
    "- Use apply to create a 'grade_point' column (A=4.0, B=3.0, C=2.0, D=1.0, F=0.0)\n",
    "- Use apply with axis=1 to calculate a 'performance_index' (weighted average: math*0.4, science*0.35, english*0.25)\n",
    "- Use apply to find the subject with the highest score for each student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472f7da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample student dataset for this exercise\n",
    "students_scores = pd.DataFrame({\n",
    "    'student_id': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve', 'Frank', 'Grace', 'Henry'],\n",
    "    'math_score': [95, 87, 92, 78, 88, 91, 85, 79],\n",
    "    'science_score': [88, 91, 85, 82, 90, 87, 89, 84],\n",
    "    'english_score': [92, 85, 89, 75, 87, 90, 83, 88]\n",
    "})\n",
    "students_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4700f240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dc8913f",
   "metadata": {},
   "source": [
    "## Complex Exercises (Advanced Projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8e7daf",
   "metadata": {},
   "source": [
    "### Complex Exercise 1: Sales Analysis\n",
    "**Objective:** Business intelligence and sales analytics\n",
    "\n",
    "**Tasks:**\n",
    "1. Calculate daily, weekly, and monthly sales totals\n",
    "2. Find top 5 products by revenue and units sold\n",
    "3. Analyze sales performance by region and salesperson\n",
    "4. Identify customer segments with highest average order value\n",
    "5. Create a pivot table showing sales by category and region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df88fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create date range for last 30 days\n",
    "dates = pd.date_range('2024-01-01', periods=30, freq='D')\n",
    "\n",
    "# Generate sample data\n",
    "n_records = 200\n",
    "sales_comprehensive = pd.DataFrame({\n",
    "    'Date': np.random.choice(dates, n_records),\n",
    "    'Product_ID': np.random.randint(1001, 1011, n_records),\n",
    "    'Product_Name': np.random.choice(['Laptop Pro', 'Wireless Mouse', 'Mechanical Keyboard', '4K Monitor', \n",
    "                                     'Noise-Canceling Headphones', 'Webcam HD', 'USB-C Hub', 'SSD 1TB', \n",
    "                                     'RAM 16GB', 'Graphics Card'], n_records),\n",
    "    'Category': np.random.choice(['Electronics', 'Accessories', 'Components'], n_records),\n",
    "    'Sales_Amount': np.random.randint(50, 2500, n_records),\n",
    "    'Units_Sold': np.random.randint(1, 10, n_records),\n",
    "    'Customer_ID': np.random.randint(10001, 10101, n_records),\n",
    "    'Customer_Segment': np.random.choice(['Premium', 'Standard', 'Budget'], n_records),\n",
    "    'Region': np.random.choice(['North', 'South', 'East', 'West', 'Central'], n_records),\n",
    "    'Salesperson_ID': np.random.randint(2001, 2011, n_records)\n",
    "})\n",
    "sales_comprehensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8959776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c55c39e",
   "metadata": {},
   "source": [
    "### Complex Exercise 2: Customer Churn Analysis\n",
    "**Objective:** Customer analytics and retention analysis\n",
    "\n",
    "**Tasks:**\n",
    "1. Calculate customer lifetime value for each customer\n",
    "2. Identify factors correlated with churn using conditional indexing\n",
    "3. Create customer segments based on usage patterns\n",
    "4. Analyze churn rates by demographic and subscription factors\n",
    "5. Build a summary report with key insights and recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdb1551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate sample customer data\n",
    "n_customers = 1000\n",
    "customers = pd.DataFrame({\n",
    "    'customer_id': range(1, n_customers + 1),\n",
    "    'age': np.random.normal(35, 12, n_customers).clip(18, 80).astype(int),\n",
    "    'gender': np.random.choice(['Male', 'Female'], n_customers),\n",
    "    'location': np.random.choice(['Urban', 'Suburban', 'Rural'], n_customers),\n",
    "    'subscription_plan': np.random.choice(['Basic', 'Premium', 'Enterprise'], n_customers, p=[0.5, 0.3, 0.2]),\n",
    "    'start_date': [datetime.now() - timedelta(days=np.random.randint(30, 1000)) for _ in range(n_customers)],\n",
    "    'monthly_fee': np.random.choice([29, 49, 99], n_customers),\n",
    "    'monthly_calls': np.random.poisson(50, n_customers),\n",
    "    'monthly_data_usage_gb': np.random.exponential(5, n_customers),\n",
    "    'support_tickets_last_6m': np.random.poisson(2, n_customers),\n",
    "    'payment_method': np.random.choice(['Credit Card', 'Debit Card', 'Bank Transfer'], n_customers),\n",
    "    'churned': np.random.choice([0, 1], n_customers, p=[0.8, 0.2])  # 20% churn rate\n",
    "})\n",
    "\n",
    "# Calculate tenure in months\n",
    "customers['tenure_months'] = ((datetime.now() - customers['start_date']).dt.days / 30).astype(int)\n",
    "customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b675f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3631b768",
   "metadata": {},
   "source": [
    "### Complex Exercise 3: E-commerce Analytics\n",
    "**Objective:** Online business metrics and customer journey analysis\n",
    "\n",
    "**Tasks:**\n",
    "1. Calculate conversion rates from browsing to purchase\n",
    "2. Analyze customer journey and identify drop-off points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c6ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate sample e-commerce data\n",
    "n_customers = 500\n",
    "n_products = 50\n",
    "n_orders = 2000\n",
    "\n",
    "# Customer behavior data\n",
    "customer_behavior = pd.DataFrame({\n",
    "    'customer_id': np.random.randint(1, n_customers + 1, n_orders),\n",
    "    'session_id': np.random.randint(1, 1001, n_orders),\n",
    "    'browsing_time_minutes': np.random.exponential(15, n_orders),\n",
    "    'pages_viewed': np.random.poisson(8, n_orders),\n",
    "    'cart_adds': np.random.poisson(2, n_orders),\n",
    "    'purchases': np.random.choice([0, 1], n_orders, p=[0.7, 0.3]),  # 30% conversion rate\n",
    "    'campaign_source': np.random.choice(['Google Ads', 'Facebook', 'Email', 'Organic', 'Direct'], n_orders),\n",
    "    'discount_applied': np.random.choice([0, 0.1, 0.15, 0.2], n_orders, p=[0.6, 0.2, 0.15, 0.05])\n",
    "})\n",
    "\n",
    "# Product catalog\n",
    "products = pd.DataFrame({\n",
    "    'product_id': range(1, n_products + 1),\n",
    "    'name': [f'Product_{i}' for i in range(1, n_products + 1)],\n",
    "    'category': np.random.choice(['Electronics', 'Clothing', 'Home', 'Books', 'Sports'], n_products),\n",
    "    'price': np.random.uniform(10, 500, n_products),\n",
    "    'inventory': np.random.randint(10, 100, n_products)\n",
    "})\n",
    "\n",
    "# Order details\n",
    "orders = pd.DataFrame({\n",
    "    'order_id': range(1, n_orders + 1),\n",
    "    'customer_id': np.random.randint(1, n_customers + 1, n_orders),\n",
    "    'order_date': [datetime.now() - timedelta(days=np.random.randint(1, 90)) for _ in range(n_orders)],\n",
    "    'total_amount': np.random.uniform(25, 1000, n_orders),\n",
    "    'shipping_cost': np.random.choice([0, 5, 10, 15], n_orders),\n",
    "    'payment_method': np.random.choice(['Credit Card', 'PayPal', 'Apple Pay'], n_orders)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec46f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
